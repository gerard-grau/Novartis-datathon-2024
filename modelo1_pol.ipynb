{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as pandas, numpy, tensorflow, and keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data\n",
    "Load the train_data.csv file and preprocess the data, including handling missing values and scaling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_data.csv')\n",
    "train_df.replace(-1.0, np.nan, inplace=True)\n",
    "train_df.replace('-1', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['launch_date', 'date', 'ind_launch_date']\n",
    "for col in date_columns:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc_columns = ['brand', 'corporation', 'country', 'therapeutic_area', 'drug_id']\n",
    "label_encoders = {}\n",
    "for col in label_enc_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregates(df, target='target'):\n",
    "    \"\"\"\n",
    "    Creates aggregate statistics and adds them directly to the input dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe to be modified\n",
    "    target : str, optional (default='target')\n",
    "        Name of the target column to aggregate\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Modified dataframe with added aggregate features\n",
    "    \"\"\"\n",
    "    # Date features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "\n",
    "    df['year_launch'] = df['launch_date'].dt.year\n",
    "    df['month_launch'] = df['launch_date'].dt.month\n",
    "\n",
    "    # # # Days since launch\n",
    "    # df['days_since_launch'] = df['date'].dt.days - df['launch_date'].dt.days\n",
    "    # # Daus since indication launch\n",
    "    # df['days_since_ind_launch'] = df['date'].dt.days - df['ind_launch_date'].dt.days\n",
    "\n",
    "    # Define the aggregation groups\n",
    "    aggregation_groups = [\n",
    "        ['country'],\n",
    "        ['brand'], \n",
    "        ['drug_id'],\n",
    "        ['country', 'brand'],\n",
    "        ['brand', 'drug_id'],\n",
    "        ['country', 'drug_id'],\n",
    "        ['country', 'brand', 'drug_id']\n",
    "    ]\n",
    "    \n",
    "    # Aggregation types\n",
    "    agg_types = ['mean', 'median', 'std', 'min', 'max']\n",
    "    \n",
    "    # Iterate through different grouping combinations\n",
    "    for group_columns in aggregation_groups:\n",
    "        # Create a unique group name for column naming\n",
    "        group_name = '_'.join(group_columns)\n",
    "        \n",
    "        # Compute aggregates\n",
    "        if len(group_columns) == 1:\n",
    "            # Simple groupby for single column\n",
    "            grouped = df.groupby(group_columns)[target].agg(agg_types)\n",
    "            grouped.columns = [f'{target}_{agg}_{group_name}' for agg in agg_types]\n",
    "            \n",
    "            # Map aggregates back to original dataframe\n",
    "            for col in grouped.columns:\n",
    "                df[col] = df[group_columns[0]].map(grouped[col])\n",
    "        else:\n",
    "            # Multi-column groupby\n",
    "            grouped = df.groupby(group_columns)[target].agg(agg_types)\n",
    "            grouped.columns = [f'{target}_{agg}_{group_name}' for agg in agg_types]\n",
    "            \n",
    "            # Map aggregates back to original dataframe\n",
    "            for col in grouped.columns:\n",
    "                df[col] = df[group_columns].apply(\n",
    "                    lambda x: grouped.loc[tuple(x), col] if tuple(x) in grouped.index else np.nan, \n",
    "                    axis=1\n",
    "                )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_rolling = create_features(train_df, label= 'target')\n",
    "train_df_rolling = create_aggregates(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_df\n",
    "# train_df_rolling.to_csv('data/train_data_rolling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df_rolling[train_df_rolling['date'] < '2022-01-01']\n",
    "test_data = train_df_rolling[train_df_rolling['date'] >= '2022-01-01']\n",
    "# train_data = train_df[train_df['date'] < '2022-01-01']\n",
    "# test_data = train_df[train_df['date'] >= '2022-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_rolling.drop(['target', 'cluster_nl', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "# X_train = train_data.drop(['target', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "y_train = train_df_rolling['target']\n",
    "\n",
    "X_test = test_data.drop(['target', 'cluster_nl', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "# X_test = test_data.drop(['target', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "y_test = test_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture\n",
    "Define the architecture of the model using a suitable neural network for time series prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model on the entire dataset without using cross-validation. Save the best model using ModelCheckpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators=1000, n_jobs=-1, random_state=33)\n",
    "model.fit(X_train, y_train, verbose=True) # Change verbose to True if you want to see it train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model_cat = CatBoostRegressor(iterations=1, \n",
    "                          learning_rate=0.03, \n",
    "                          depth=6, \n",
    "                          random_seed=33, \n",
    "                          verbose=100)  # Adjust verbosity as needed\n",
    "\n",
    "model_cat.fit(X_train, y_train, verbose=True)  # Set `verbose` to control training logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_lgbm = LGBMRegressor(n_estimators=1, \n",
    "                      learning_rate=0.03, \n",
    "                      num_leaves=31, \n",
    "                      random_state=33)\n",
    "\n",
    "model_lgbm.fit(X_train, y_train)  # Adjust verbosity with frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cat.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lgbm.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "def _CYME(df: pd.DataFrame) -> float:\n",
    "    \"\"\" Compute the CYME metric, that is 1/2(median(yearly error) + median(monthly error))\"\"\"\n",
    "\n",
    "    yearly_agg = df.groupby(\"cluster_nl\")[[\"target\", \"prediction\"]].sum().reset_index()\n",
    "    yearly_error = abs((yearly_agg[\"target\"] - yearly_agg[\"prediction\"])/yearly_agg[\"target\"]).median()\n",
    "\n",
    "    monthly_error = abs((df[\"target\"] - df[\"prediction\"])/df[\"target\"]).median()\n",
    "\n",
    "    return 1/2*(yearly_error + monthly_error)\n",
    "\n",
    "\n",
    "def _metric(df: pd.DataFrame) -> float:\n",
    "    \"\"\"Compute metric of submission.\n",
    "\n",
    "    :param df: Dataframe with target and 'prediction', and identifiers.\n",
    "    :return: Performance metric\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # Split 0 actuals - rest\n",
    "    zeros = df[df[\"zero_actuals\"] == 1]\n",
    "    recent = df[df[\"zero_actuals\"] == 0]\n",
    "\n",
    "    # weight for each group\n",
    "    zeros_weight = len(zeros)/len(df)\n",
    "    recent_weight = 1 - zeros_weight\n",
    "\n",
    "    # Compute CYME for each group\n",
    "    return round(recent_weight*_CYME(recent) + zeros_weight*min(1,_CYME(zeros)), 8)\n",
    "\n",
    "\n",
    "def compute_metric(submission: pd.DataFrame) -> Tuple[float, float]:\n",
    "    \"\"\"Compute metric.\n",
    "\n",
    "    :param submission: Prediction. Requires columns: ['cluster_nl', 'date', 'target', 'prediction']\n",
    "    :return: Performance metric.\n",
    "    \"\"\"\n",
    "\n",
    "    submission[\"date\"] = pd.to_datetime(submission[\"date\"])\n",
    "    submission = submission[['cluster_nl', 'date', 'target', 'prediction', 'zero_actuals']]\n",
    "\n",
    "    return _metric(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test_data.copy()\n",
    "\n",
    "validation[\"prediction\"] = model.predict(validation[X_train.columns])\n",
    "\n",
    "# Assign column [\"zero_actuals\"] in the depending if in your\n",
    "# split the cluster_nl has already had actuals on train or not\n",
    "existing_clusters = train_data['cluster_nl'].unique()\n",
    "validation['zero_actuals'] = (~validation['cluster_nl'].isin(existing_clusters)).astype(int)\n",
    "\n",
    "print(\"Performance:\", compute_metric(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test_data.copy()\n",
    "\n",
    "validation[\"prediction\"] = model_cat.predict(validation[X_train.columns])\n",
    "\n",
    "# Assign column [\"zero_actuals\"] in the depending if in your\n",
    "# split the cluster_nl has already had actuals on train or not\n",
    "existing_clusters = train_data['cluster_nl'].unique()\n",
    "validation['zero_actuals'] = (~validation['cluster_nl'].isin(existing_clusters)).astype(int)\n",
    "\n",
    "print(\"Performance:\", compute_metric(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test_data.copy()\n",
    "\n",
    "validation[\"prediction\"] = model_lgbm.predict(validation[X_train.columns])\n",
    "\n",
    "# Assign column [\"zero_actuals\"] in the depending if in your\n",
    "# split the cluster_nl has already had actuals on train or not\n",
    "existing_clusters = train_data['cluster_nl'].unique()\n",
    "validation['zero_actuals'] = (~validation['cluster_nl'].isin(existing_clusters)).astype(int)\n",
    "\n",
    "print(\"Performance:\", compute_metric(validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model\n",
    "Evaluate the model's performance on a validation set or using other suitable metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/submission_data.csv')\n",
    "test_df.replace(-1.0, np.nan, inplace=True)\n",
    "test_df.replace('-1', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[numeric_cols] = test_df[numeric_cols].fillna(test_df[numeric_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['launch_date', 'date', 'ind_launch_date']\n",
    "for col in date_columns:\n",
    "    test_df[col] = pd.to_datetime(test_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_enc_columns:\n",
    "    le = label_encoders[col]\n",
    "    test_df[col] = le.fit_transform(test_df[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_rolling = create_aggregates(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_rolling = test_df_rolling.drop(['target', 'cluster_nl', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "# X_test = test_data.drop(['target', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "# y_test = test_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_rolling.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df_rolling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_str'] = test_df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.DataFrame({'date_str':test_df['date_str'], 'cluster_nl':test_df['cluster_nl'], 'prediction': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = pd.read_csv('data/submission_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv.drop('prediction', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = pd.merge(submission_csv, submission_data, left_on=['date', 'cluster_nl'], right_on=['date_str', 'cluster_nl'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
