{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as pandas, numpy, tensorflow, and keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data\n",
    "Load the train_data.csv file and preprocess the data, including handling missing values and scaling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_data.csv')\n",
    "train_df.replace(-1.0, np.nan, inplace=True)\n",
    "train_df.replace('-1', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['che_pc_usd', 'che_perc_gdp', 'insurance_perc_che', 'population',\n",
       "       'prev_perc', 'price_month', 'price_unit', 'public_perc_che', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['brand', 'che_pc_usd', 'che_perc_gdp', 'cluster_nl', 'corporation',\n",
       "       'country', 'launch_date', 'date', 'drug_id', 'ind_launch_date',\n",
       "       'indication', 'insurance_perc_che', 'population', 'prev_perc',\n",
       "       'price_month', 'price_unit', 'public_perc_che', 'therapeutic_area',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['launch_date', 'date', 'ind_launch_date']\n",
    "for col in date_columns:\n",
    "    train_df[col] = pd.to_datetime(train_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['launch_year'] = train_df['launch_date'].dt.year\n",
    "train_df['launch_month'] = train_df['launch_date'].dt.month\n",
    "train_df['date_year'] = train_df['date'].dt.year\n",
    "train_df['date_month'] = train_df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc_columns = ['brand', 'corporation', 'country', 'therapeutic_area', 'drug_id']\n",
    "label_encoders = {}\n",
    "for col in label_enc_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df[train_df['date'] < '2022-01-01']\n",
    "test_data = train_df[train_df['date'] >= '2022-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['target', 'cluster_nl', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "# X_train = train_data.drop(['target', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_test = test_data.drop(['target', 'cluster_nl', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "# X_test = test_data.drop(['target', 'launch_date', 'date', 'ind_launch_date', 'indication'], axis=1)\n",
    "y_test = test_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture\n",
    "Define the architecture of the model using a suitable neural network for time series prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AE_MLP(nn.Module):\n",
    "    def __init__(self, num_columns, num_labels, hidden_units, dropout_rates):\n",
    "        super(AE_MLP, self).__init__()\n",
    "        \n",
    "        # Initial batch normalization\n",
    "        self.batch_norm0 = nn.BatchNorm1d(num_columns)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_noise = nn.Dropout(dropout_rates[0])\n",
    "        self.encoder_dense = nn.Linear(num_columns, hidden_units[0])\n",
    "        self.encoder_batch_norm = nn.BatchNorm1d(hidden_units[0])\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_dropout = nn.Dropout(dropout_rates[1])\n",
    "        self.decoder_dense = nn.Linear(hidden_units[0], num_columns)\n",
    "        \n",
    "        # AE branch\n",
    "        self.x_ae_dense = nn.Linear(num_columns, hidden_units[1])\n",
    "        self.x_ae_batch_norm = nn.BatchNorm1d(hidden_units[1])\n",
    "        self.x_ae_dropout = nn.Dropout(dropout_rates[2])\n",
    "        self.out_ae_dense = nn.Linear(hidden_units[1], num_labels)\n",
    "        \n",
    "        # Concatenation and main branch\n",
    "        concat_input_dim = num_columns + hidden_units[0]\n",
    "        self.concat_batch_norm = nn.BatchNorm1d(concat_input_dim)\n",
    "        self.concat_dropout = nn.Dropout(dropout_rates[3])\n",
    "        \n",
    "        # Adjusted hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        input_dim = concat_input_dim  # Start with concatenated dimension\n",
    "        for i in range(2, len(hidden_units)):\n",
    "            self.hidden_layers.append(nn.Linear(input_dim, hidden_units[i]))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(hidden_units[i]))\n",
    "            self.hidden_layers.append(nn.Dropout(dropout_rates[i + 2]))\n",
    "            input_dim = hidden_units[i]  # Update input_dim for next layer\n",
    "        \n",
    "        # Output layer\n",
    "        self.out_dense = nn.Linear(input_dim, num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.batch_norm0(x)\n",
    "        \n",
    "        # Encoder\n",
    "        encoder = self.encoder_noise(x0)\n",
    "        encoder = self.encoder_dense(encoder)\n",
    "        encoder = self.encoder_batch_norm(encoder)\n",
    "        encoder = F.silu(encoder)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder = self.decoder_dropout(encoder)\n",
    "        decoder = self.decoder_dense(decoder)\n",
    "        \n",
    "        # AE branch\n",
    "        x_ae = self.x_ae_dense(decoder)\n",
    "        x_ae = self.x_ae_batch_norm(x_ae)\n",
    "        x_ae = F.silu(x_ae)\n",
    "        x_ae = self.x_ae_dropout(x_ae)\n",
    "        out_ae = torch.sigmoid(self.out_ae_dense(x_ae))\n",
    "        \n",
    "        # Main branch\n",
    "        x_concat = torch.cat([x0, encoder], dim=1)\n",
    "        x = self.concat_batch_norm(x_concat)\n",
    "        x = self.concat_dropout(x)\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                x = F.silu(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                \n",
    "        out = torch.sigmoid(self.out_dense(x))\n",
    "        \n",
    "        return decoder, out_ae, out\n",
    "\n",
    "# Example usage:\n",
    "# model = AE_MLP(num_columns, num_labels, hidden_units, dropout_rates)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# criterion_decoder = nn.MSELoss()\n",
    "# criterion_ae_action = nn.BCEWithLogitsLoss()\n",
    "# criterion_action = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model on the entire dataset without using cross-validation. Save the best model using ModelCheckpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AE_MLP(num_columns\u001b[38;5;241m=\u001b[39mX_train_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, hidden_units\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m], dropout_rates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define loss functions and optimizer\u001b[39;00m\n\u001b[1;32m      9\u001b[0m criterion_decoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "epochs = 50\n",
    "\n",
    "# Instantiate the model\n",
    "model = AE_MLP(num_columns=X_train_tensor.shape[1], num_labels=1, hidden_units=[256, 256, 256], dropout_rates=[0.2]*7)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss functions and optimizer\n",
    "criterion_decoder = nn.MSELoss()\n",
    "criterion_ae_action = nn.BCEWithLogitsLoss()  # Changed to BCEWithLogitsLoss\n",
    "criterion_action = nn.BCEWithLogitsLoss()     # Changed to BCEWithLogitsLoss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_maes = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Move data to device\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        decoder_out, out_ae, out = model(X_batch)\n",
    "\n",
    "        # Compute losses\n",
    "        loss_decoder = criterion_decoder(decoder_out, X_batch)\n",
    "        loss_ae_action = criterion_ae_action(out_ae, y_batch)\n",
    "        loss_action = criterion_action(out, y_batch)\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss_decoder + loss_ae_action + loss_action\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            # Move data to device\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            decoder_out, out_ae, out = model(X_batch)\n",
    "\n",
    "            # Compute losses\n",
    "            loss_decoder = criterion_decoder(decoder_out, X_batch)\n",
    "            loss_ae_action = criterion_ae_action(out_ae, y_batch)\n",
    "            loss_action = criterion_action(out, y_batch)\n",
    "\n",
    "            loss = loss_decoder + loss_ae_action + loss_action\n",
    "\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            val_mae += torch.sum(torch.abs(torch.sigmoid(out) - y_batch)).item()  # Apply sigmoid to outputs\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_mae /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_maes.append(val_mae)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the validation MAE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(val_maes, label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "Evaluate the model's performance on a validation set or using other suitable metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
